{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sl', 'es', 'el', 'nl', 'hu', 'it', 'bg', 'sk', 'da', 'sv', 'cs', 'lt', 'de', 'en', 'pl', 'fr', 'fi', 'lv', 'pt', 'et', 'ro']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/workspace/lang-detect/txt/\"\n",
    "dir_list = os.listdir(data_path)\n",
    "print(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        if len(lines) > 1:\n",
    "            return lines[1].strip(\"\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 s, sys: 1.62 s, total: 4.6 s\n",
      "Wall time: 4.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data, labels = [], []\n",
    "for dir_name in dir_list:\n",
    "    files_list = os.listdir(data_path + dir_name)\n",
    "    for f in files_list:\n",
    "        sent = read_data(data_path + dir_name + \"/\" + f)\n",
    "        if sent:\n",
    "            data.append(sent)\n",
    "            labels.append(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length of data', 186458)\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of data\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Zahteva za za\\xc5\\xa1\\xc4\\x8dito poslanske imunitete: glej zapisnik', 'sl')\n",
      "('Ordine del giorno della prossima seduta: vedi verbale', 'it')\n",
      "('EU external strategy on Passenger Name Record (PNR) (debate) ', 'en')\n",
      "('Contenedores perdidos en el mar y compensaci\\xc3\\xb3n (debate) ', 'es')\n",
      "('5. Przyst\\xc4\\x85pienie Bu\\xc5\\x82garii i Rumunii do umowy o wsp\\xc3\\xb3\\xc5\\x82pracy i unii celnej mi\\xc4\\x99dzy EWG i Republik\\xc4\\x85 San Marino (g\\xc5\\x82osowanie)', 'pl')\n",
      "('Stemmeforklaringer', 'da')\n",
      "('20. Accordo di partenariato CE/Repubblica di Kiribati nel settore della pesca (votazione) ', 'it')\n",
      "('15. Raming van de inkomsten en uitgaven voor het begrotingsjaar 2011 - Afdeling I - Europees Parlement (', 'nl')\n",
      "('13. Aplicaci\\xc3\\xb3n del principio de reconocimiento mutuo de resoluciones en materia penal (', 'es')\n",
      "('6. Fishing opportunities and financial contribution provided for in the EU-S\\xc3\\xa3o Tom\\xc3\\xa9 and Pr\\xc3\\xadncipe Fisheries Partnership Agreement (', 'en')\n",
      "('10. A m\\xc3\\xa9lytengeri hal\\xc3\\xa1llom\\xc3\\xa1nyok kezel\\xc3\\xa9se (', 'hu')\n",
      "('2. Conditions for access to the network for cross-border exchanges in electricity (', 'en')\n",
      "('1. Statistika Spole\\xc4\\x8denstv\\xc3\\xad t\\xc3\\xbdkaj\\xc3\\xadc\\xc3\\xad se zahrani\\xc4\\x8dn\\xc3\\xadho obchodu se t\\xc5\\x99et\\xc3\\xadmi zem\\xc4\\x9bmi a zru\\xc5\\xa1en\\xc3\\xad na\\xc5\\x99\\xc3\\xadzen\\xc3\\xad Rady (', 'cs')\n",
      "('\\xce\\x95\\xcf\\x80\\xce\\xb9\\xcf\\x83\\xce\\xba\\xcf\\x8c\\xcf\\x80\\xce\\xb7\\xcf\\x83\\xce\\xb7 \\xcf\\x84\\xce\\xb7\\xcf\\x82 \\xce\\x92\\xce\\xb5\\xce\\xbb\\xce\\xb3\\xce\\xb9\\xce\\xba\\xce\\xae\\xcf\\x82 \\xce\\xa0\\xcf\\x81\\xce\\xbf\\xce\\xb5\\xce\\xb4\\xcf\\x81\\xce\\xaf\\xce\\xb1\\xcf\\x82 \\xcf\\x84\\xce\\xbf\\xcf\\x85 \\xce\\xa3\\xcf\\x85\\xce\\xbc\\xce\\xb2\\xce\\xbf\\xcf\\x85\\xce\\xbb\\xce\\xaf\\xce\\xbf\\xcf\\x85 (\\xcf\\x83\\xcf\\x85\\xce\\xb6\\xce\\xae\\xcf\\x84\\xce\\xb7\\xcf\\x83\\xce\\xb7) ', 'el')\n",
      "('Az elt\\xc5\\xb1nt gyermekek megtal\\xc3\\xa1l\\xc3\\xa1s\\xc3\\xa1t c\\xc3\\xa9lz\\xc3\\xb3 sz\\xc3\\xbcks\\xc3\\xa9g-egy\\xc3\\xbcttm\\xc5\\xb1k\\xc3\\xb6d\\xc3\\xa9s (\\xc3\\xadr\\xc3\\xa1sbeli nyilatkozat): l\\xc3\\xa1sd a jegyz\\xc5\\x91k\\xc3\\xb6nyvet', 'hu')\n",
      "('Term\\xc3\\xadny nasleduj\\xc3\\xbacich rokovan\\xc3\\xad: pozri z\\xc3\\xa1pisnicu', 'sk')\n",
      "('Balso\\xc5\\xa1anas laiks', 'lv')\n",
      "('14. Bosnia ja Hertsegoviina (', 'et')\n",
      "('G\\xc5\\x82osowanie', 'pl')\n",
      "('Karistused ebaseaduslikult riigis viibivate kolmandate riikide kodanike t\\xc3\\xb6\\xc3\\xb6andjatele (arutelu) ', 'et')\n"
     ]
    }
   ],
   "source": [
    "# Check data sample\n",
    "import random\n",
    "rand_indices = random.sample(range(len(data)),  20)\n",
    "for i in rand_indices:\n",
    "    print(data[i],labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aftale mellem EF og japans lin p\\xc3\\xb6yt\\xc3\\xa4kirjan hyv\\xc3\\xa4ksyminen '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "    # remove punctuations\n",
    "    text = re.sub(\"[()/.:?,!@#$%\\\"']\", \"\", text)\n",
    "    new_string = \"\"\n",
    "    for token in text.split():\n",
    "        # check if no alphabet character\n",
    "        if re.search(\"[a-zA-Z]\",token):\n",
    "            # if not in all-caps, make it lower case\n",
    "            if not token.isupper():\n",
    "                token = token.lower()\n",
    "            new_string += (token + \" \")\n",
    "    return new_string\n",
    "\n",
    "test_text = \"12. Aftale mellem EF\\\" 'og' Japans !2### ( 100.9 lin 1233 ??? p\\xc3\\xb6yt\\xc3\\xa4kirjan hyv\\xc3\\xa4ksyminen:\"\n",
    "preprocess(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 s, sys: 19.9 ms, total: 2.06 s\n",
      "Wall time: 2.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(data)):\n",
    "    data[i] = preprocess(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predlog splo\\xc5\\xa1nega prora\\xc4\\x8duna za leto oddelek III ', '\\xc5\\xbdenske in vodenje podjetij ', 'razmere na bli\\xc5\\xbenjem vzhodugaza glasovanje ', 'predlo\\xc5\\xbeitev dokumentov glej zapisnik ', 'javna ponudba vrednostnih papirjev in uskladitev zahtev v zvezi s preglednostjo razprava ']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dictionary for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "lang_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for token in data[i].split():\n",
    "        if (labels[i] in lang_dict) and (token in lang_dict[labels[i]]):\n",
    "            lang_dict[labels[i]][token] += 1\n",
    "        else:\n",
    "            lang_dict[labels[i]][token] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5324"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_dict['en']['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('el', 709)\n",
      "('fr', 4734)\n",
      "('bg', 463)\n",
      "('nl', 5100)\n",
      "('ro', 5109)\n",
      "('pt', 4177)\n",
      "('lv', 6182)\n",
      "('sv', 5643)\n",
      "('de', 5617)\n",
      "('it', 4807)\n",
      "('hu', 6836)\n",
      "('sk', 6478)\n",
      "('et', 6730)\n",
      "('lt', 6428)\n",
      "('en', 4035)\n",
      "('pl', 6481)\n",
      "('sl', 6390)\n",
      "('cs', 6000)\n",
      "('fi', 7015)\n",
      "('da', 5240)\n",
      "('es', 4256)\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size in each language\n",
    "for key in lang_dict.keys():\n",
    "    print(key, len(lang_dict[key].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('lang_dict.json', 'w') as outfile:\n",
    "    json.dump(lang_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
